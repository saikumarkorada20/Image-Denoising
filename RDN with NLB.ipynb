{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":14,"outputs":[{"output_type":"stream","text":"/kaggle/input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv\n/kaggle/input/dl-project/0001_NOISY_SRGB_010.PNG\n/kaggle/input/dl-project/0001_GT_SRGB_011.PNG\n/kaggle/input/dl-project/0001_GT_SRGB_010.PNG\n/kaggle/input/dl-project/0001_NOISY_SRGB_011.PNG\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport argparse\nimport torch.optim as optim\nimport torchvision.utils as utils\nfrom torch.utils.data import DataLoader","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ground_truth = list()\nnoise_images = list()\nfor dirname, _, filenames in os.walk('/kaggle/input/dl-project'):\n    for filename in filenames:\n        if filename[5:].startswith('GT'):\n            ground_truth.append(filename)\n            noise_images.append(filename.replace('GT', 'NOISY'))\nprint(ground_truth)\nprint(noise_images)","execution_count":16,"outputs":[{"output_type":"stream","text":"['0001_GT_SRGB_011.PNG', '0001_GT_SRGB_010.PNG']\n['0001_NOISY_SRGB_011.PNG', '0001_NOISY_SRGB_010.PNG']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_split = int(0.9*len(ground_truth))\ngt_train, gt_val = ground_truth[:val_split], ground_truth[val_split:]\nnoise_train, noise_val = noise_images[:val_split], noise_images[val_split:]\nprint(gt_train, gt_val)\nprint(noise_train, noise_val)","execution_count":17,"outputs":[{"output_type":"stream","text":"['0001_GT_SRGB_011.PNG'] ['0001_GT_SRGB_010.PNG']\n['0001_NOISY_SRGB_011.PNG'] ['0001_NOISY_SRGB_010.PNG']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport os.path\nimport numpy as np\nimport random\nimport h5py\nimport torch\n#import cv2\nfrom PIL import Image\nimport glob\nimport torch.utils.data as udata\n#from utils import data_augmentation\n\nimport torchvision.transforms as transforms\n\ndef normalize(data):\n    return data/255.\n\ndef Im2Patch(img, win, stride=1):\n    k = 0\n    endc = img.shape[0]\n    endw = img.shape[1]\n    endh = img.shape[2]\n    patch = img[:, 0:endw-win+0+1:stride, 0:endh-win+0+1:stride]\n    TotalPatNum = patch.shape[1] * patch.shape[2]\n    Y = np.zeros([endc, win*win,TotalPatNum], np.float32)\n    for i in range(win):\n        for j in range(win):\n            patch = img[:,i:endw-win+i+1:stride,j:endh-win+j+1:stride]\n            Y[:,k,:] = np.array(patch[:]).reshape(endc, TotalPatNum)\n            k = k + 1\n    return Y.reshape([endc, win, win, TotalPatNum])\n\ndef prepare_data(root, noise_list , gt_list,  train, patch_size = 256, stride = 200, aug_times=1):\n    if train == True:\n        # train\n        print('processing training data')\n        scales = [1]\n\n        root = '../input/dl-project/'\n        h5f = h5py.File('train.h5', 'w')\n    else:\n        # validation\n        print('processing validation data')\n        scales = [1]\n\n        root = '../input/dl-project/'\n        h5f = h5py.File('validation.h5', 'w')\n\n    train_num = 0\n    for i in range(len(noise_list)):\n\n        n_img = Image.open(os.path.join(root, noise_list[i]))\n        gt_img = Image.open(os.path.join(root, gt_list[i]))\n\n        # Convert to numpy\n        n_img = np.array(n_img, dtype=np.float16)\n        gt_img = np.array(gt_img, dtype=np.float16)\n\n        h, w, c = n_img.shape\n        for k in range(len(scales)):\n            n_img = n_img.transpose(2, 0, 1)\n            n_img = np.float16(normalize(n_img))\n            n_patches = Im2Patch(n_img, win=patch_size, stride=stride)\n\n            gt_img = gt_img.transpose(2, 0, 1)\n            gt_img = np.float16(normalize(gt_img))\n            gt_patches = Im2Patch(gt_img, win=patch_size, stride=stride)\n\n            #print(\"file: %s scale %.1f # samples: %d\" % (noise_list[i], scales[k], n_patches.shape[3]*aug_times))\n            for n in range(n_patches.shape[3]):\n                patches = np.concatenate((n_patches[:,:,:,n], gt_patches[:,:,:,n]), axis = 0)\n                data = patches.copy()\n                for m in range(aug_times):\n                    data_aug = data\n                    h5f.create_dataset(str(train_num)+\"_aug_%d\" % (m), data=data_aug)\n                    train_num += 1\n                    #print(train_num)\n    h5f.close()\n    if train == True:\n        print('training set, # samples %d\\n' % train_num)\n    else:\n        print('validation set, # samples %d\\n' % train_num)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prepare_data(root = \"a\" , noise_list = noise_list , gt_list  = gt_list )","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(udata.Dataset):\n    def __init__(self, train=True):\n        super(Dataset, self).__init__()\n        self.train = train\n        self.output_size = (48, 48)\n        if self.train:\n            h5f = h5py.File('/kaggle/working/train.h5', 'r')\n        else:\n            h5f = h5py.File('/kaggle/working/validation.h5', 'r')\n        self.keys = list(h5f.keys())\n        random.shuffle(self.keys)\n        h5f.close()\n    def __len__(self):\n        return len(self.keys)\n        \n    def preprocess(self, x):\n        dh = np.random.randint(1, 200, size=1)\n        dw = np.random.randint(1, 200, size=1)\n        x = x[:, dh[0]:dh[0]+48, dw[0]:dw[0]+48]    #48, 200\n        #mode = np.random.randint(0, 2, size=1)\n        #x = data_augmentation(x, mode)\n        y = x\n        return y\n        \n    def __getitem__(self, index):\n        if self.train:\n            h5f = h5py.File('/kaggle/working/train.h5', 'r')\n        else:\n            h5f = h5py.File('/kaggle/working/validation.h5', 'r')\n        key = self.keys[index]\n        data = np.array(h5f[key])\n        data = self.preprocess(data)\n        h5f.close()\n        return torch.Tensor(data)\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.init as init\n  \nclass RDB_Conv(nn.Module):\n    def __init__(self, in_C, growRate, kSize=3):\n        super(RDB_Conv, self).__init__()\n        self.conv = nn.Sequential(*[\n            nn.Conv2d(in_C, growRate, kSize, padding=(kSize-1)//2, stride=1),\n            nn.ReLU()\n        ])\n        # self.conv = nn.Sequential(\n        #     nn.BatchNorm2d(in_C),\n        #     Modulecell(in_channels=in_C,out_channels=growRate,kernel_size=kSize))\n        # self.conv = nn.Sequential(*[\n        #     nn.Conv2d(in_C, growRate, kSize, padding=(kSize-1)//2, stride=1),\n        #     nn.BatchNorm2d(growRate),\n        #     nn.PReLU()\n        # ])\n    def forward(self, x):\n        out = self.conv(x)\n        return torch.cat((x, out), 1)\n        \nclass RDB(nn.Module):\n    def __init__(self, growRate0, growRate, nConvLayers, kSize=3):\n        super(RDB, self).__init__()\n        G0 = growRate0\n        G = growRate\n        C = nConvLayers\n        convs = []\n        for i in range(C):\n            convs.append(RDB_Conv(G0 + i*G, G, kSize))\n        self.convs = nn.Sequential(*convs)\n        #Local Feature Fusion\n        self.lff = nn.Conv2d(G0 + C*G, G0, 1, padding=0, stride=1)\n        \n    def forward(self, x):\n        y = self.lff(self.convs(x)) + x\n        return y\n    \nclass NonLocalBlock2D(nn.Module):\n    def __init__(self, in_channels, inter_channels):\n        super(NonLocalBlock2D, self).__init__()\n        self.in_channels = in_channels\n        self.inter_channels = inter_channels\n        self.g = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n        self.W = nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0)\n        nn.init.constant(self.W.weight, 0)\n        nn.init.constant(self.W.bias, 0)\n        self.theta = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n        self.phi = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n    def forward(self, x):\n        batch_size = x.size(0)\n        g_x = self.g(x).view(batch_size, self.inter_channels, -1)        \n        g_x = g_x.permute(0,2,1)\n        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n        theta_x = theta_x.permute(0,2,1)\n        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n        f = torch.matmul(theta_x, phi_x)\n        f_div_C = F.softmax(f, dim=1)\n        y = torch.matmul(f_div_C, g_x)\n        y = y.permute(0,2,1).contiguous()\n        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n        W_y = self.W(y)\n        z = W_y + x\n        return z\n    \nclass NLMaskBranchDownUp(nn.Module):\n    def __init__(self,growRate0, growRate, nConvLayers, nRDBs, kSize=3):\n        super(NLMaskBranchDownUp, self).__init__()\n        G0 = growRate0\n        G = growRate\n        C = nConvLayers\n        m = int(nRDBs/4)\n        MB_RB1 = []\n        MB_RB1.append(NonLocalBlock2D(G0, G0))\n        for i in range(m):\n            MB_RB1.append(RDB(G0, G, C, kSi1ze))\n        MB_Down = []\n        MB_Down.append(nn.Conv2d(G0,G0, 3, stride=2, padding=1))        \n        MB_RB2 = []\n        for i in range(2*m):\n            MB_RB2.append(RDB(G0, G, C, kSize))\n        MB_Up = []\n        MB_Up.append(nn.ConvTranspose2d(G0,G0, 6, stride=2, padding=2))   \n        MB_RB3 = []\n        for i in range(m):\n            MB_RB3.append(RDB(G0, G, C, kSize))\n        MB_1x1conv = []\n        MB_1x1conv.append(nn.Conv2d(G0,G0, 1, padding=0, bias=True))\n        MB_sigmoid = []\n        MB_sigmoid.append(nn.Sigmoid())\n        self.MB_RB1 = nn.Sequential(*MB_RB1)\n        self.MB_Down = nn.Sequential(*MB_Down)\n        self.MB_RB2 = nn.Sequential(*MB_RB2)\n        self.MB_Up  = nn.Sequential(*MB_Up)\n        self.MB_RB3 = nn.Sequential(*MB_RB3)\n        self.MB_1x1conv = nn.Sequential(*MB_1x1conv)\n        self.MB_sigmoid = nn.Sequential(*MB_sigmoid)\n    \n    def forward(self, x):\n        x_RB1 = self.MB_RB1(x)\n        x_Down = self.MB_Down(x_RB1)\n        x_RB2 = self.MB_RB2(x_Down)\n        x_Up = self.MB_Up(x_RB2)\n        x_preRB3 = x_RB1 + x_Up\n        x_RB3 = self.MB_RB3(x_preRB3)\n        x_1x1 = self.MB_1x1conv(x_RB3)\n        mx = self.MB_sigmoid(x_1x1)\n        return mx\n       \nclass RDN(nn.Module):\n    def __init__(self, growRate0,growRate, RDBkSize,nConvLayers,nRDBs):\n        super(RDN, self).__init__()\n        G0 = growRate0\n        kSize = RDBkSize\n        G = growRate\n        C = nConvLayers\n        D = nRDBs\n        #D, C, G = (20, 6, 32)\n        D, C, G = (16, 8, 64)\n        self.RDB_num = D\n        #Shallow Feature Extraction\n        self.sfe1 = nn.Conv2d(3, G0, kSize, padding=(kSize-1)//2, stride=1)\n        self.sfe2 = nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n        #Residual Dense Blocks\n        self.RDBs = nn.ModuleList()\n        for i in range(D):\n            self.RDBs.append(RDB(G0, G, C, kSize))\n        #self.Mask = []\n        self.Mask = (NLMaskBranchDownUp(G0, G, C,nRDBs, kSize=3))\n        #Global Feature Fusion\n        self.gff = nn.Sequential(*[\n            nn.Conv2d(D*G0, G0, 1, padding=0, stride=1),\n            nn.Conv2d(G0, G0, kSize, padding=(kSize-1)//2, stride=1)\n        ])\n        #self.non_local = Self_Att(G0, 'relu')\n        self.out_conv = nn.Conv2d(G0, 3, kSize, padding=(kSize-1)//2, stride=1)\n        self.init_params()\n\n    def init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                #init.kaiming_normal_(m.weight, mode='fan_out')\n                init.normal(m.weight, std=0.01)\n                # init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.ConvTranspose2d):\n                #init.kaiming_normal_(m.weight, mode='fan_out')\n                init.normal_(m.weight, std=0.01)\n                # init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.01)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n    def forward(self, x):\n        f1 = self.sfe1(x)\n        y = self.sfe2(f1)\n        f2= self.Mask(y)\n        RDB_out = []\n        for i in range(self.RDB_num):\n            y = self.RDBs[i](y)\n            RDB_out.append(y)\n        y = self.gff(torch.cat(RDB_out, 1))\n        #y = self.non_local(y)\n        y = y*f2\n        y = self.out_conv(f1 + y)\n        \n        y += x\n        return y","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom skimage.measure.simple_metrics import compare_psnr\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm') != -1:\n        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n        nn.init.constant(m.bias.data, 0.0)\n\ndef batch_PSNR(img, imclean, data_range):\n    Img = img.data.cpu().numpy().astype(np.float32)\n    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n    PSNR = 0\n    for i in range(Img.shape[0]):\n        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n    return (PSNR/Img.shape[0])\n\ndef data_augmentation(image, mode):\n    # #out = np.transpose(image, (1,2,0))\n    # out = image\n    # if mode == 0:\n    #     # original\n    #     out = out\n    # elif mode == 1:\n    #     # flip up and down\n    #     out = np.flipud(out)\n    # elif mode == 2:\n    #     # rotate counterwise 90 degree\n    #     out = np.rot90(out)\n    # elif mode == 3:\n    #     # rotate 90 degree and flip up and down\n    #     out = np.rot90(out)\n    #     out = np.flipud(out)\n    # elif mode == 4:\n    #     # rotate 180 degree\n    #     out = np.rot90(out, k=2)\n    # elif mode == 5:\n    #     # rotate 180 degree and flip\n    #     out = np.rot90(out, k=2)\n    #     out = np.flipud(out)\n    # elif mode == 6:\n    #     # rotate 270 degree\n    #     out = np.rot90(out, k=3)\n    # elif mode == 7:\n    #     # rotate 270 degree and flip\n    #     out = np.rot90(out, k=3)\n    #     out = np.flipud(out)\n    # #return np.transpose(out, (2,0,1))\n    # return out\n\n    if mode == 0:\n        # original\n        out = image\n    elif mode == 1:\n        # flip up and down\n        out = np.flipud(image)\n    elif mode == 2:\n        # rotate counterwise 90 degree\n        out = np.rot90(image, k=2)\n\n    return out\n\ndef SSIM(x, y):\n    C1 = 0.01 ** 2\n    C2 = 0.03 ** 2\n\n    mu_x = nn.AvgPool2d(3, 1)(x)\n    mu_y = nn.AvgPool2d(3, 1)(y)\n    mu_x_mu_y = mu_x * mu_y\n    mu_x_sq = mu_x.pow(2)\n    mu_y_sq = mu_y.pow(2)\n\n    sigma_x = nn.AvgPool2d(3, 1)(x * x) - mu_x_sq\n    sigma_y = nn.AvgPool2d(3, 1)(y * y) - mu_y_sq\n    sigma_xy = nn.AvgPool2d(3, 1)(x * y) - mu_x_mu_y\n\n    SSIM_n = (2 * mu_x_mu_y + C1) * (2 * sigma_xy + C2)\n    SSIM_d = (mu_x_sq + mu_y_sq + C1) * (sigma_x + sigma_y + C2)\n    SSIM = SSIM_n / SSIM_d\n\n    return torch.clamp((1 - SSIM) / 2, 0, 1)\n\ndef update_lr(ori_lr, epoch):\n    #current_lr = ori_lr * (1 - epoch/40.0)**0.9\n    current_lr = ori_lr * (0.1 ** ((epoch) // 40))\n    return current_lr","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport argparse\nimport torch.optim as optim\nimport torchvision.utils as utils\nfrom torch.utils.data import DataLoader","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = \"RDN_e40_16\"\nbatch_size = 4\nlr = 1e-4\nepochs = 3","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nmodel_dir = os.path.join(\"/kaggle/working/\", model_name)\nprint('create checkpoint directory %s...' % model_dir)\nif not os.path.exists(model_dir):\n    os.makedirs(model_dir)","execution_count":25,"outputs":[{"output_type":"stream","text":"create checkpoint directory /kaggle/working/RDN_e40_16...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepare_data(root = \"adarsh\" , noise_list = noise_train , gt_list = gt_train , train = True)\nprepare_data(root = \"adarsh\" , noise_list = noise_val , gt_list = gt_val, train = False)","execution_count":26,"outputs":[{"output_type":"stream","text":"processing training data\ntraining set, # samples 364\n\nprocessing validation data\nvalidation set, # samples 364\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loading training dataset ...\\n')\ndataset_train = Dataset(train=True)\nloader_train = DataLoader(dataset=dataset_train, num_workers=4 , batch_size = batch_size, shuffle=True)\nnum = len(dataset_train)\nprint(\"# of training samples: %d\\n\" % int(num))","execution_count":27,"outputs":[{"output_type":"stream","text":"Loading training dataset ...\n\n# of training samples: 364\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loading validation dataset ...\\n')\ndataset_test = Dataset(train=False)\nloader_test = DataLoader(dataset=dataset_test, num_workers=4 , batch_size = batch_size, shuffle=True)\nnum = len(dataset_test)\nprint(\"# of validation samples: %d\\n\" % int(num))","execution_count":28,"outputs":[{"output_type":"stream","text":"Loading validation dataset ...\n\n# of validation samples: 364\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build model\nnet = RDN(64,64,3,8, 3)\n\nnum_params = 0\nfor parm in net.parameters():\n    num_params += parm.numel()\nprint(net)\nprint('[Network %s] Total number of parameters : %.3f M' % (model_name, num_params / 1e6))\n# Move to GPU\ndevice_ids = [0]\nmodel = nn.DataParallel(net, device_ids=device_ids).cuda()\n#model.load_state_dict(torch.load(os.path.join('logs/', opt.name, '40_net.pth')))  # !!!\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)  #weight_decay=opt.weight_decay","execution_count":32,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:145: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","name":"stderr"},{"output_type":"stream","text":"RDN(\n  (sfe1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (sfe2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (RDBs): ModuleList(\n    (0): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (3): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (4): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (5): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (6): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (7): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (8): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (9): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (10): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (11): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (12): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (13): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (14): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (15): RDB(\n      (convs): Sequential(\n        (0): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (1): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (2): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (3): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (4): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (5): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (6): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n        (7): RDB_Conv(\n          (conv): Sequential(\n            (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (1): ReLU()\n          )\n        )\n      )\n      (lff): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (Mask): NLMaskBranchDownUp(\n    (MB_RB1): Sequential(\n      (0): NonLocalBlock2D(\n        (g): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        (W): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        (theta): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        (phi): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (MB_Down): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n    (MB_RB2): Sequential()\n    (MB_Up): Sequential(\n      (0): ConvTranspose2d(64, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n    )\n    (MB_RB3): Sequential()\n    (MB_1x1conv): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (MB_sigmoid): Sequential(\n      (0): Sigmoid()\n    )\n  )\n  (gff): Sequential(\n    (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (out_conv): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)\n[Network RDN_e40_16] Total number of parameters : 22.181 M\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validator(model, loader_data = loader_test):\n    ave_loss_val = 0\n    ave_psnr_val = 0\n    ave_ssim_val = 0\n\n    for j, data in enumerate(loader_test, 0):\n        # training step\n        time1 = time.time()\n        noise_img_val = data[:, :3, :, :]\n        gt_img_val = data[:, 3:, :, :]\n\n        noise_img_val, gt_img_val = noise_img_val.cuda(), gt_img_val.cuda()\n        res_val = noise_img_val - gt_img_val\n\n        # Validation set\n        pred_res_val = model(noise_img_val)\n\n        loss1_val = torch.mean(torch.abs(pred_res_val - gt_img_val))\n        loss2_val = torch.mean(SSIM(pred_res_val, gt_img_val))\n        loss_val = loss1_val #0.75*loss1 + 0.25*loss2\n        #Validation set\n\n        #Validation set\n        result_val = torch.clamp(pred_res_val, 0., 1.)\n        psnr_val = batch_PSNR(result_val, gt_img_val, 1.)\n\n        ave_loss_val = (ave_loss_val*j + loss_val.item()) / (j+1)\n        ave_psnr_val = (ave_psnr_val*j + psnr_val) / (j+1)\n        ave_ssim_val = (ave_ssim_val*j + 1-loss2_val.item()*2) / (j+1)\n        #Validation set\n\n    return ave_loss_val, ave_psnr_val, ave_ssim_val","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nstep = 0\nprint(f\"Training on {len(loader_train)} samples and validating on {len(loader_test)} samples\")\n\nfor epoch in range(epochs):\n    # set learning rate\n    current_lr = update_lr(lr, epoch)\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = current_lr\n    print('learning rate %f' % current_lr)\n\n    # train\n    model.train()\n    start_time = time.time()\n    \n    ave_loss = 0\n    ave_psnr = 0\n    ave_ssim = 0\n\n    '''\n    for j, data in enumerate(loader_test, 0):\n    data = data[:, :3, :, :]\n    # training step\n    time1 = time.time()\n    noise_img_val = data[:, :3, :, :]\n    gt_img_val = data[:, 3:, :, :]\n\n    noise_img_val, gt_img_val = noise_img_val.cuda(), gt_img_val.cuda()\n    res_val = noise_img_val - gt_img_val\n    #res_val = res_val.cuda()\n    '''\n    \n    for i, data in enumerate(loader_train, 0):\n        # training step\n        time1 = time.time()\n        model.zero_grad()\n        optimizer.zero_grad()\n\n        noise_img = data[:, :3, :, :]\n        gt_img = data[:, 3:, :, :]\n\n        noise_img, gt_img = noise_img.cuda(), gt_img.cuda()\n        res = noise_img - gt_img\n        pred_res = model(noise_img)\n\n        loss1 = torch.mean(torch.abs(pred_res - gt_img))\n        loss2 = torch.mean(SSIM(pred_res, gt_img))\n        loss = loss1 #0.75*loss1 + 0.25*loss2\n        \n        loss.backward()\n        optimizer.step()\n\n        # evaluate\n        #result = torch.clamp(noise_img-pred_res, 0., 1.)\n        result = torch.clamp(pred_res, 0., 1.)\n        psnr_train = batch_PSNR(result, gt_img, 1.)\n\n        ave_loss = (ave_loss*i + loss.item()) / (i+1)\n        ave_psnr = (ave_psnr*i + psnr_train) / (i+1)\n        ave_ssim = (ave_ssim*i + 1-loss2.item()*2) / (i+1)\n \n\n        if i == len(loader_train)-1:\n            time2 = time.time()\n            print(\"Training details: [epoch %d][%d/%d] Time taken: %.3f loss: %.4f PSNR_train: %.4f SSIM_train: %.4f\" %\n                (epoch+1, i+1, len(loader_train), (time2 - start_time), ave_loss, ave_psnr, ave_ssim))\n            ave_loss_val, ave_psnr_val, ave_ssim_val = validator(model)\n            time3 = time.time()\n            print(\"Testing Details: Time taken: %.3f loss: %.4f PSNR_test: %.4f SSIM_test: %.4f\" %\n                ( (time3 - time2), ave_loss_val, ave_psnr_val, ave_ssim_val))\n            print(f'Total time for epoch: {time3 - start_time}')\n        if step % 1000 == 0:\n            torch.save(model.state_dict(), os.path.join(model_dir, 'latest_net.pth'))\n        step += 1\n        #result = torch.clamp(noise_img-pred_res, 0., 1.)\n\n    # save model\n    if epoch%2 == 0:\n        save_name = '%d_net.pth' % (epoch+1)\n        torch.save(model.state_dict(), os.path.join(model_dir, save_name))","execution_count":34,"outputs":[{"output_type":"stream","text":"Training on 91 samples and validating on 91 samples\nlearning rate 0.000100\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n","name":"stderr"},{"output_type":"stream","text":"Training details: [epoch 1][91/91] Time taken: 18.378 loss: 0.0181 PSNR_train: 32.7643 SSIM_train: 0.7529\nTesting Details: Time taken: 6.350 loss: 0.0137 PSNR_test: 35.1370 SSIM_test: 0.8478\nTotal time for epoch: 24.72796630859375\nlearning rate 0.000100\nTraining details: [epoch 2][91/91] Time taken: 18.197 loss: 0.0122 PSNR_train: 36.2488 SSIM_train: 0.8818\nTesting Details: Time taken: 6.243 loss: 0.0116 PSNR_test: 36.6396 SSIM_test: 0.8919\nTotal time for epoch: 24.440308332443237\nlearning rate 0.000100\nTraining details: [epoch 3][91/91] Time taken: 18.095 loss: 0.0115 PSNR_train: 36.7668 SSIM_train: 0.8935\nTesting Details: Time taken: 6.218 loss: 0.0112 PSNR_test: 37.0263 SSIM_test: 0.8990\nTotal time for epoch: 24.31334352493286\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}